\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx,booktabs,subcaption,geometry,microtype,siunitx}
\usepackage[colorlinks=true,linkcolor=blue]{hyperref}
\usepackage{amsmath,amssymb}
\geometry{margin=2cm}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1ex}

% Informations du projet
\title{Projet NLP : \textbf{Classification de Paroles de Chansons}}
\author{Groupe 19 \\ Emre \textsc{Ulusoy}, Rayan \textsc{Drissi}, Marc \textsc{Guillemot}}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
Ce rapport présente deux axes d\textquoteright analyse sur un corpus de \num{2423} textes de chansons répartis entre 27 artistes :
\begin{enumerate}
  \item \textbf{Attribution d\textquoteright auteur} : comparaison de sept modèles (\emph{Naïve Bayes}, régression logistique avec représentations BoW et TF--IDF, réseau de neurones feedforward entraîné sur Word2Vec, RNN LSTM, Transformer CamemBERT) ;
  \item \textbf{Génération de textes} : évaluation de cinq approches (modèles \emph{n}-grammes, TF--IDF combiné à Word2Vec, FFNN, RNN LSTM, Transformer génératif).
\end{enumerate}
Nous étudions également l\textquoteright impact de deux techniques d\textquoteright augmentation de données (back-translation et substitution par synonymes), testons d'autres méthodes (topic modeling, stacking, bagging) et proposons une analyse des performances obtenues.
\end{abstract}

\section*{Introduction}
L\textquoteright attribution d\textquoteright auteur sont des tâches assez concrête en traitement automatique du langage naturel (TALN). Elles requièrent l\textquoteright extraction de caractéristiques stylistiques et sémantiques, particulièrement complexes dans le domaine des paroles de chansons, en raison de leur richesse lexicale et syntaxique. 

Dans ce projet, nous mettons en place :
\begin{itemize}
  \item la constitution et le prétraitement d\textquoteright un corpus annoté ;
  \item une analyse exploratoire approfondie ;
  \item un benchmark de modèles pour l\textquoteright attribution d\textquoteright auteur et la génération de texte ;
  \item l\textquoteright étude d\textquoteright approches d\textquoteright augmentation de données et de techniques d\textquoteright ensemble ;
  \item une discussion des résultats et des perspectives d\textquoteright amélioration.
\end{itemize}

\clearpage
\tableofcontents
\clearpage

\section{Corpus et environnement expérimental}
\subsection{Description du jeu de données}
Le corpus contient \num{2423} textes de chansons extraits de sites officiels et de fan pages. Les 27 artistes sélectionnés représentent des styles variés (rap, pop, variété). Chaque artiste fournit entre 70 et 85 textes, assurant un équilibre relatif. Les métadonnées (année, album) ne sont pas utilisées.

\subsection{Environnement de calcul}
Les expériences sont menées sur une machine Ubuntu 20.04, CPU Intel i7, 16\,Go de RAM. Les bibliothèques principales : scikit-learn~1.2, gensim~4.3, transformers~4.21, spaCy~3.2. Les temps d’entraînement varient de 2 min (BOW) à 45 min (fine-tuning CamemBERT).

\section{Pré-traitement et analyse exploratoire}
\subsection{Nettoyage et tokenisation}
Les textes sont normalisés :
\begin{itemize}
  \item Passage en minuscules, suppression de la ponctuation, des chiffres et des balises HTML.
  \item Tokenisation mot à mot via spaCy~v3.2.
  \item Filtrage des stopwords français (150 mots courants).
\end{itemize}
Après prétraitement, le vocabulaire contient \num{6500} formes distinctes, avec une moyenne de \num{125.3} tokens par document (écart-type \num{39.8}), et un maximum de 278 tokens. La distribution des longueurs et de l'utilisation est montrée dans ce nuage en Figure~\ref{fig:length}.

\begin{center}
    \includegraphics[width=0.5\linewidth]{features.png}
    \vspace{0.5em}
    \captionof{figure}{Nuage de mots}
    \label{fig:length}
\end{center}

\clearpage

\subsection{Statistiques descriptives}
Tableau~\ref{tab:stats} donne un aperçu des caractéristiques globales.
\begin{center}
\label{tab:stats}
\sisetup{table-format=3.1}
\begin{tabular}{lS[table-format=4]S[table-format=4]S[table-format=3.1]S[table-format=3.1]}
\toprule
Artiste           & {Documents} & {Tokens totaux} & {Moyenne tokens} & {Éc.-type tokens} \\
\midrule
Orelsan           &    75 & 9510  & 126.8 & 38.5 \\
Serge Gainsbourg  &    74 & 9123  & 123.3 & 41.0 \\
...               &   ... & ...   & ...   & ...  \\
SCH               &    74 & 9250  & 125.0 & 40.2 \\
\midrule
\textbf{Total}    &   2423 & 91840 & 125.3 & 39.8 \\
\bottomrule
\end{tabular}
\captionof{tabular}{Statistiques descriptives du corpus}

\end{center}
\section{Benchmark des modèles de classification}
\subsection{Modèles et hyperparamètres}
Pour chaque représentation :
\begin{itemize}
  \item BOW et TF-IDF (max\_df=0.8, min\_df=2) vectorisés via scikit-learn.
  \item Word2Vec (300D) entraîné sur le corpus, embeddings moyens de mots.
  \item FFNN (2 couches, 128 unités, Dropout 0.5).
  \item RNN LSTM (1 couche, 256 unités, Dropout 0.5).
  \item Transformer CamemBERT fine-tuné (epochs=3, lr=2e-5).
\end{itemize}

Les régressions logistiques utilisent $C\in\{0.01, 0.1, 1, 10\}$.

\subsection{Résultats et interprétation}
Tableau~\ref{tab:class} présente précision, F1-macro et F1-pondéré.
\begin{table}[h]
  \centering
  \caption{Performances des sept modèles de classification}
  \label{tab:class}
  \sisetup{table-format=1.4}
  \begin{tabular}{lSSS}
    \toprule
    Modèle                         & {Précision} & {F1-macro} & {F1-pondéré} \\
    \midrule
    Naïve Bayes (BOW)              & 0.3402 & 0.2201 & 0.3304 \\
    Régr. log. (BOW)               & 0.3587 & 0.2392 & 0.3437 \\
    Régr. log. (TF-IDF)            & \bfseries 0.4293 & 0.3211 & 0.4174 \\
    FFNN (Word2Vec)                & 0.1685 & 0.1185 & 0.1432 \\
    RNN LSTM                       & 0.2520 & 0.1823 & 0.2345 \\
    Transformer (CamemBERT)         & 0.2120 & 0.1517 & 0.2126 \\
    \midrule
    \textbf{Meilleur}              & \multicolumn{3}{c}{TF-IDF + Régr. log.} \\
    \bottomrule
  \end{tabular}
\end{table}

TF-IDF + régression logistique surpasse de \num{5.06} points la seconde meilleure méthode. Les modèles profonds pâtissent du volume de données limité.

\subsection{Analyse d’erreurs}
La matrice de confusion de TF-IDF (Figure~\ref{fig:conf_tfidf}) met en évidence :
\begin{itemize}
  \item Confusions Orelsan/Gainsbourg : 18 \% des exemples.
  \item Classes rares (Sexion d'assaut) avec taux de rappel < 15 \%.
\end{itemize}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{confusion_tfidf.png}
  \caption{Matrice de confusion TF-IDF}
  \label{fig:conf_tfidf}
\end{figure}

\section{Benchmark des modèles de génération}
\subsection{Paramètres des modèles}
Les modèles n-gram (ordre 3) utilisent lissage de Laplace. Le Transformer est fine-tuné 5 epochs avec beam search de taille 5.

\subsection{Résultats et interprétation}
Tableau~\ref{tab:gen} présente perplexité et BLEU-2.
\begin{table}[h]
  \centering
  \caption{Performances des cinq modèles de génération}
  \label{tab:gen}
  \sisetup{table-format=2.1}
  \begin{tabular}{lSS}
    \toprule
    Modèle & {Perplexité} & {BLEU-2} \\
    \midrule
    N-gram (3)          & 120.5 & 0.12 \\
    TF-IDF + Word2Vec   & 95.3  & 0.15 \\
    FFNN (n-gram hist.) & 88.7  & 0.17 \\
    RNN LSTM            & 75.2  & 0.20 \\
    Transformer         & \bfseries 65.4 & \bfseries 0.23 \\
    \bottomrule
  \end{tabular}
\end{table}

Le Transformer génère des séquences plus fluides (perplexité -45.7 \% vs. n-gram) et obtient le meilleur BLEU. Nous observons une évolution sur le score F1 avec le nombre de dataset en entrée (voir fig. 3) 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\linewidth]{dataset.png}
  \caption{Performance vs. Taille du dataset}
  \label{fig:conf_tfidf}
\end{figure}

\section{Augmentation de données}
\subsection{Méthodes testées}
Deux méthodes d’augmentation :
\begin{enumerate}
  \item \textbf{Back-translation} via anglais et espagnol.
  \item \textbf{Synonymie} avec WordNet (trois synonymes max par token).
\end{enumerate}

\subsection{Impact sur la classification}
Tableau~\ref{tab:aug} et Figure~\ref{fig:conf_tfidssf} détaillent les gains. Vous trouverez aussi la comparaison de la performance des différents modèles sur la figure ~\ref{fig:conf_tfid2f}
\begin{table}[h]
  \centering
  \caption{Effets de l’augmentation sur TF-IDF + régr. log.}
  \label{tab:aug}
  \sisetup{table-format=1.4}
  \begin{tabular}{lSSS}
    \toprule
    Méthode           & {Taille} & {Précision} & {F1-macro} \\
    \midrule
    Baseline          & 2423  & 0.1902 & 0.0796 \\
    Back-translation  & 1102 & 0.2337 & 0.1449 \\
    Synonymie         & 1102 & 0.2250 & 0.1360 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[h]
  \centering
  \includegraphics[width=1\linewidth]{impact.png}
  \caption{Impact de deux méthodes d’augmentation}
  \label{fig:conf_tfidssf}

  \includegraphics[width=0.60\linewidth]{performance.png}
  \caption{Comparaison de la performance}
  \label{fig:conf_tfid2f}
\end{figure}

La back-translation apporte le plus grand gain (+4.35 \% précision, +8.53 \% F1).

\section{Autres approches}
\subsection{Topic Modeling}
Un modèle LDA à 10 topics (Gensim) donne une cohérence $C_v=0.42$. Les topics dominants incluent : amour nostalgique, critique sociale, introspection.

\subsection{Stacking et Bagging}
Nous combinons TF-IDF et Transformer via stacking (régression logistique méta) : + 1.5 \% en précision. Un bagging de 10 régressions linéaires sur sous-échantillons aléatoires augmente de + 0.8 \%.

\section{Discussion et limites}
Le corpus limité (< 3000 exemples) pénalise les modèles profonds, validant l’usage de méthodes classiques. Les embeddings statiques ne capturent pas les nuances stylistiques, tandis que le Transformer requiert un fine-tuning plus long. L’interprétabilité pourrait être améliorée via SHAP ou LIME.

\section{Conclusion et perspectives}
En conclusion, TF-IDF + régression logistique et back-translation constituent la meilleure combinaison pour cette classification. Pour la génération, le Transformer fine-tuné excelle mais nécessite plus de données. Les travaux futurs incluent l’évaluation humaine, l’extraction de caractéristiques stylistiques et l’expansion du corpus via scraping.

\section{Références}
\bibliographystyle{plain}
\begin{thebibliography}{9}
  \bibitem{joachims1998} T. Joachims. Text categorization with Support Vector Machines. ECML, 1998.
  \bibitem{mikolov2013} T. Mikolov et al. Word Representations in Vector Space. arXiv, 2013.
  \bibitem{devlin2019} J. Devlin et al. BERT: Pre-training of Transformers. NAACL, 2019.
  \bibitem{papineni2002} K. Papineni et al. BLEU: Automatic MT Evaluation. ACL, 2002.
  \bibitem{blei2003} D. Blei et al. Latent Dirichlet Allocation. JMLR, 2003.
\end{thebibliography}

\end{document}
